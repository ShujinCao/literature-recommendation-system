{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "134e4c62",
   "metadata": {},
   "source": [
    "# Sentence-BERT Embedding Generation\n",
    "\n",
    "This notebook generates dense paper embeddings using a pretrained Sentence-BERT model and writes them to `data/processed/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ed4c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>topic_primary</th>\n",
       "      <th>paper_recency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Military staff happy event.</td>\n",
       "      <td>Senior nor ahead consider. Success light capit...</td>\n",
       "      <td>2005</td>\n",
       "      <td>MentalHealth</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Possible standard former whether smile.</td>\n",
       "      <td>Maintain hair general let. Character material ...</td>\n",
       "      <td>2001</td>\n",
       "      <td>HIV</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Shake evidence yeah cover.</td>\n",
       "      <td>Season education easy space argue. Stage inter...</td>\n",
       "      <td>2001</td>\n",
       "      <td>MCH</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Customer lay politics sure pretty.</td>\n",
       "      <td>Detail herself easy miss red. Nor arm line for...</td>\n",
       "      <td>2011</td>\n",
       "      <td>CVD</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Write animal forward dark tax if.</td>\n",
       "      <td>Health memory budget matter simply set. None c...</td>\n",
       "      <td>2015</td>\n",
       "      <td>NCD</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                    title  \\\n",
       "0         0              Military staff happy event.   \n",
       "1         1  Possible standard former whether smile.   \n",
       "2         2               Shake evidence yeah cover.   \n",
       "3         3       Customer lay politics sure pretty.   \n",
       "4         4        Write animal forward dark tax if.   \n",
       "\n",
       "                                            abstract  year topic_primary  \\\n",
       "0  Senior nor ahead consider. Success light capit...  2005  MentalHealth   \n",
       "1  Maintain hair general let. Character material ...  2001           HIV   \n",
       "2  Season education easy space argue. Stage inter...  2001           MCH   \n",
       "3  Detail herself easy miss red. Nor arm line for...  2011           CVD   \n",
       "4  Health memory budget matter simply set. None c...  2015           NCD   \n",
       "\n",
       "   paper_recency  \n",
       "0             20  \n",
       "1             24  \n",
       "2             24  \n",
       "3             14  \n",
       "4             10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Directory for preprocessed data\n",
    "PRE_DIR = Path(\"../data/preprocessed\")\n",
    "\n",
    "# Load cleaned/preprocessed papers\n",
    "papers = pd.read_csv(PRE_DIR / \"papers_cleaned.csv\")\n",
    "\n",
    "papers.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ea4f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:03<00:00,  9.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 384)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load lightweight Sentence-BERT model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert abstracts to strings & list\n",
    "texts = papers[\"abstract\"].astype(str).tolist()\n",
    "\n",
    "# Generate normalized embeddings for cosine similarity use\n",
    "paper_embeddings = model.encode(\n",
    "    texts,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "paper_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80b90f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings and mapping to data/preprocessed/\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings to file\n",
    "np.save(PRE_DIR / \"paper_embeddings.npy\", paper_embeddings)\n",
    "\n",
    "# Save mapping of paper_id to embedding row index\n",
    "mapping = pd.DataFrame({\n",
    "    \"paper_id\": papers[\"paper_id\"],\n",
    "    \"index\": range(len(papers)),\n",
    "})\n",
    "mapping.to_csv(PRE_DIR / \"paper_id_to_index.csv\", index=False)\n",
    "\n",
    "print(\"Saved embeddings and mapping to data/preprocessed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f38d1f-2c80-4ff7-9920-36dce6435e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
