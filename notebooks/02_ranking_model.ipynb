{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f98018fd-ca69-4af7-9cd1-8f44552c904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/jackcao/Documents/github/literature-recommendation-system\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Project root\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "PRE_DIR = project_root / \"data\" / \"preprocessed\"\n",
    "MODEL_DIR = project_root / \"models\"\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865ec17f-8b64-4f14-9355-513f51f8140e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   paper_id                                    title  \\\n",
       " 0         0              Military staff happy event.   \n",
       " 1         1  Possible standard former whether smile.   \n",
       " 2         2               Shake evidence yeah cover.   \n",
       " 3         3       Customer lay politics sure pretty.   \n",
       " 4         4        Write animal forward dark tax if.   \n",
       " \n",
       "                                             abstract  year topic_primary  \\\n",
       " 0  Senior nor ahead consider. Success light capit...  2005  MentalHealth   \n",
       " 1  Maintain hair general let. Character material ...  2001           HIV   \n",
       " 2  Season education easy space argue. Stage inter...  2001           MCH   \n",
       " 3  Detail herself easy miss red. Nor arm line for...  2011           CVD   \n",
       " 4  Health memory budget matter simply set. None c...  2015           NCD   \n",
       " \n",
       "    paper_recency  \n",
       " 0             20  \n",
       " 1             24  \n",
       " 2             24  \n",
       " 3             14  \n",
       " 4             10  ,\n",
       "    user_id  paper_id     event            timestamp  label\n",
       " 0       60        21     click  2024-03-05 06:23:17      1\n",
       " 1       38       760  open_pdf  2025-01-01 23:28:11      0\n",
       " 2      179       359     click  2025-08-18 12:13:33      1\n",
       " 3       66       986     click  2025-03-14 18:53:32      1\n",
       " 4      140       624     click  2025-06-20 03:57:24      1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "papers = pd.read_csv(PRE_DIR / \"papers_preprocessed.csv\")\n",
    "users = pd.read_csv(PRE_DIR / \"users_preprocessed.csv\")\n",
    "inter = pd.read_csv(PRE_DIR / \"interactions_preprocessed.csv\")\n",
    "\n",
    "# Load embedding matrix\n",
    "embeddings = np.load(PRE_DIR / \"paper_embeddings.npy\")\n",
    "\n",
    "papers.head(), inter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f1f8839-4815-4b62-85ac-431887ed5e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jackcao/Documents/github/literature-recommendation-system\n",
      "[DEBUG] Looking for preprocessed data in: /Users/jackcao/Documents/github/literature-recommendation-system/data/preprocessed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src.models.candidate_gen import CandidateGenerator\n",
    "\n",
    "cg = CandidateGenerator(pre_dir=PRE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c4cb04-a353-41a1-a99b-8b3b684858c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>paper_recency</th>\n",
       "      <th>topic_primary</th>\n",
       "      <th>topic_match</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>565</td>\n",
       "      <td>0.680768</td>\n",
       "      <td>5</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>972</td>\n",
       "      <td>0.664908</td>\n",
       "      <td>4</td>\n",
       "      <td>NCD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0.635828</td>\n",
       "      <td>9</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>694</td>\n",
       "      <td>0.633624</td>\n",
       "      <td>15</td>\n",
       "      <td>MCH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0.625718</td>\n",
       "      <td>17</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  paper_id  similarity  paper_recency topic_primary  topic_match  \\\n",
       "0        0       565    0.680768              5   Respiratory            1   \n",
       "1        0       972    0.664908              4           NCD            1   \n",
       "2        0       122    0.635828              9        Cancer            0   \n",
       "3        0       694    0.633624             15           MCH            0   \n",
       "4        0        92    0.625718             17        Cancer            0   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rows = []\n",
    "\n",
    "for user_id in users[\"user_id\"].tolist():\n",
    "\n",
    "    # Get top 200 candidates for this user\n",
    "    paper_ids, sims = cg.get_top_n(user_id, n=200)\n",
    "\n",
    "    # Convert paper_id list â†’ DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"user_id\": user_id,\n",
    "        \"paper_id\": paper_ids,\n",
    "        \"similarity\": sims\n",
    "    })\n",
    "\n",
    "    # Merge with paper metadata\n",
    "    df = df.merge(papers[[\"paper_id\", \"paper_recency\", \"topic_primary\"]], on=\"paper_id\", how=\"left\")\n",
    "\n",
    "    # Add topic match feature\n",
    "    u = users[users.user_id == user_id].iloc[0]\n",
    "    df[\"topic_match\"] = (\n",
    "        (df[\"topic_primary\"] == u[\"research_focus_1\"]) |\n",
    "        (df[\"topic_primary\"] == u[\"research_focus_2\"])\n",
    "    ).astype(int)\n",
    "\n",
    "    # Label: 1 if user interacted with paper\n",
    "    interacted = inter[inter.user_id == user_id][\"paper_id\"].tolist()\n",
    "    df[\"label\"] = df[\"paper_id\"].isin(interacted).astype(int)\n",
    "\n",
    "    train_rows.append(df)\n",
    "\n",
    "train_df = pd.concat(train_rows, ignore_index=True)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c6764c-8ac8-4bcb-97b6-3bda1848ecf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 3), 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [\"similarity\", \"paper_recency\", \"topic_match\"]\n",
    "label_col = \"label\"\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df[label_col]\n",
    "\n",
    "# Group queries (each user is a group)\n",
    "group = train_df.groupby(\"user_id\").size().tolist()\n",
    "\n",
    "X.shape, len(group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba6a5d7d-ced6-4011-9f0a-b9642c49003e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 283\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000, number of used features: 3\n",
      "Saved trained ranking model to: /Users/jackcao/Documents/github/literature-recommendation-system/models/ranker.txt\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(X, label=y, group=group)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"ndcg_eval_at\": [5],\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 32,\n",
    "    \"max_depth\": -1,\n",
    "}\n",
    "\n",
    "ranker_model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=200,\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model_path = MODEL_DIR / \"ranker.txt\"\n",
    "ranker_model.save_model(str(model_path))\n",
    "\n",
    "print(\"Saved trained ranking model to:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a0bd2b8-84fe-4348-87a7-8e3a558767af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5: 0.05007601422055757\n",
      "NDCG@5: 0.27071279329466563\n"
     ]
    }
   ],
   "source": [
    "# Simple evaluation: generate top 5 and compare to interactions\n",
    "\n",
    "def evaluate_user(user_id):\n",
    "    paper_ids, sims = cg.get_top_n(user_id, n=200)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"paper_id\": paper_ids,\n",
    "        \"similarity\": sims,\n",
    "    }).merge(papers[[\"paper_id\", \"paper_recency\", \"topic_primary\"]], on=\"paper_id\")\n",
    "\n",
    "    u = users[users.user_id == user_id].iloc[0]\n",
    "    df[\"topic_match\"] = (\n",
    "        (df[\"topic_primary\"] == u[\"research_focus_1\"]) |\n",
    "        (df[\"topic_primary\"] == u[\"research_focus_2\"])\n",
    "    ).astype(int)\n",
    "\n",
    "    X_user = df[feature_cols]\n",
    "\n",
    "    scores = ranker_model.predict(X_user)\n",
    "    df[\"score\"] = scores\n",
    "\n",
    "    top5 = df.sort_values(\"score\", ascending=False).head(5)[\"paper_id\"].tolist()\n",
    "    interacted = inter[inter.user_id == user_id][\"paper_id\"].tolist()\n",
    "\n",
    "    recall5 = len(set(top5) & set(interacted)) / max(1, len(interacted))\n",
    "\n",
    "    # NDCG@5 using actual labels\n",
    "    labels = df[\"paper_id\"].isin(interacted).astype(int).tolist()\n",
    "    ndcg5 = ndcg_score([labels], [df[\"score\"].tolist()], k=5)\n",
    "\n",
    "    return recall5, ndcg5\n",
    "\n",
    "recalls, ndcgs = [], []\n",
    "for uid in users[\"user_id\"].tolist():\n",
    "    r, n = evaluate_user(uid)\n",
    "    recalls.append(r)\n",
    "    ndcgs.append(n)\n",
    "\n",
    "print(\"Recall@5:\", np.mean(recalls))\n",
    "print(\"NDCG@5:\", np.mean(ndcgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572d5cd-9bd5-4ad1-855d-ae36c090e56e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lit-rs)",
   "language": "python",
   "name": "lit-rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
